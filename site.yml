# (c) 2016 DataNexus Inc.  All Rights Reserved
---
# Build our kafka and zookeeper host groups
- name: Create kafka and zookeeper host groups
  hosts: "{{host_inventory}}"
  gather_facts: no
  tasks:
    # load the 'local variables file', if one was defined, to get any variables
    # we might need from that file when constructing our host groups
    - name: Load local variables file
      include_vars:
        file: "{{local_vars_file}}"
      when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
    # then, build our host groups
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - name: kafka
          - name: zookeeper
      when: inventory_type == 'dynamic'
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - { name: kafka, node_list: "{{host_inventory}}" }
          - { name: zookeeper, inventory_file: "{{zookeeper_inventory_file | default(none)}}" }
      when: inventory_type == 'static'

# Collect some Zookeeper related facts and determine the "private" IP addresses of
# the nodes in the Zookeeper ensemble (from their "public" IP addresses and the `data_iface`
# variable that was passed in as part of this playbook run) if a list of "public"  Zookeeper
# IP addresses was passed in.
- name: Gather facts from Zookeeper host group (if defined)
  hosts: zookeeper:&zookeeper_nodes
  tasks: []

# If we're provisioning, then deploy Kafka to the nodes in the `host_inventory` that was
# passed in (if there is more than one node passed in, those nodes will be configured as
# a single Kafka cluster)
- name: Install/configure Kafka server(s)
  hosts: kafka:&kafka_nodes
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - provisioning: false
    - combined_package_list: "{{ (default_packages|default([])) | union(kafka_package_list) | union((install_packages_by_tag|default({})).kafka|default([])) }}"
  pre_tasks:
    # if we're provisioning, execute the following `pre_tasks`
    - block:
      # first, load the local variables file (if one was defined); this will initialize
      # the variables used in our playbook (and override any values in the 'vars/kafka.yml'
      # file with redefined values from the 'local_vars_file', if any)
      - name: Load local variables file (if defined)
        include_vars:
          file: "{{local_vars_file}}"
        when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
      # then, restart the network (unless the skip_network_restart was set)
      # and gather some facts about our Kafka node(s)
      - name: Ensure the network interfaces are up on our Kafka node(s)
        service:
          name: network
          state: restarted
        become: true
        when: not (skip_network_restart is defined or skip_network_restart)
      - name: Gather facts from the Kafka node(s)
        setup:
      # next, we obtain the interface names for our data_iface
      # and api_iface (provided an interface description was provided for each)
      - include_role:
          name: get-iface-names
        vars:
          iface_descriptions: "{{iface_description_array}}"
        when: not (iface_description_array is undefined or iface_description_array == [])
      # and now that we know we have our data_iface identified, we can construct
      # the list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
      - set_fact:
          zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
      when: provisioning | bool
      # if we're provisioning a RHEL machine, then we need to ensure that
      # it's subscribed before we can install anything (if it hasn't been
      # registered already, of course, if that's the case then we can skip
      # this step)
    - block:
      - redhat_subscription:
          state: present
          username: "{{rhel_username}}"
          password: "{{rhel_password}}"
          consumer_id: "{{rhel_consumer_id}}"
        become: true
        when: rhel_username is defined and rhel_password is defined and rhel_consumer_id is defined
      when: (provisioning | bool) and ansible_distribution == 'RedHat'
  # Now that we have all of the facts we need, we can run the roles that are used to
  # deploy and configure Kafka if we're provisioning a new cluster
  roles:
    - role: get-iface-addr
      iface_name: "{{data_iface}}"
      as_fact: "data_addr"
      when: provisioning | bool
    - role: get-iface-addr
      iface_name: "{{api_iface}}"
      as_fact: "api_addr"
      when: provisioning | bool
    - role: setup-web-proxy
      when: provisioning | bool
    - role: add-local-repository
      yum_repository: "{{yum_repo_url}}"
      when: (provisioning | bool) and yum_repo_url is defined
    - role: install-packages
      package_list: "{{combined_package_list}}"
      when: provisioning | bool
    - role: dn-kafka
      when: provisioning | bool

# If we're adding/removing topics, then connect to the Kafka cluster and perform the
# necessary actions to do so
- name: Configure Kafka topics
  hosts: kafka:&kafka_nodes
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - modify_topics: false
  pre_tasks:
    # if we're modifying the topics managed by the Kafka cluster (adding new topics
    # or removing existing ones), then execute the following `pre_tasks`
    - block:
      # first, load the local variables file (if one was defined); this will initialize
      # the variables used in our playbook (and override any values in the 'vars/kafka.yml'
      # file with redefined values from the 'local_vars_file', if any)
      - name: Load local variables file (if defined)
        include_vars:
          file: "{{local_vars_file}}"
        when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
      - name: Gather facts from the Kafka node(s)
        setup:
      # next, we obtain the interface names for our data_iface
      # and api_iface (provided an interface description was provided for each)
      - include_role:
          name: get-iface-names
        vars:
          iface_descriptions: "{{iface_description_array}}"
        when: not (iface_description_array is undefined or iface_description_array == [])
      # and now that we know we have our data_iface identified, we can construct
      # the list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
      - set_fact:
          zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
      when: modify_topics | bool
  # Now that we have all of the facts we need we can proceed to modify the topics
  # if that's what we're doing (add new topics to or remove existing topics from
  # the cluster)
  roles:
    - role: modify-topics
      when: modify_topics | bool

# if we're adding/removing connectors then connect to the Kafka cluster and perform
# the necessary actions to do so
- name: Configure Kafka connectors
  hosts: kafka:&kafka_nodes
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - modify_connectors: false
  pre_tasks:
    # if we're modifying the connectors managed by the Kafka cluster (adding new connectors
    # or removing existing ones), then execute the following `pre_tasks`
    - block:
      # first, load the local variables file (if one was defined); this will initialize
      # the variables used in our playbook (and override any values in the 'vars/kafka.yml'
      # file with redefined values from the 'local_vars_file', if any)
      - name: Load local variables file (if defined)
        include_vars:
          file: "{{local_vars_file}}"
        when: not (local_vars_file is undefined or local_vars_file is none or local_vars_file | trim == '')
      - name: Gather facts from the Kafka node(s)
        setup:
      # next, we obtain the interface names for our data_iface
      # and api_iface (provided an interface description was provided for each)
      - include_role:
          name: get-iface-names
        vars:
          iface_descriptions: "{{iface_description_array}}"
        when: not (iface_description_array is undefined or iface_description_array == [])
      # and now that we know we have our data_iface identified, we can construct
      # the list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
      - set_fact:
          zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
      when: modify_connectors | bool
  # Now that we have all of the facts we need we can proceed to modify the topics
  # if that's what we're doing (add new topics to or remove existing topics from
  # the cluster)
  roles:
    - role: get-iface-addr
      iface_name: "{{data_iface}}"
      as_fact: "data_addr"
      when: modify_connectors | bool
    - role: get-iface-addr
      iface_name: "{{api_iface}}"
      as_fact: "api_addr"
      when: modify_connectors | bool
    - role: modify-connectors
      when: modify_connectors | bool
